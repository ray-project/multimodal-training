# Condition 3: Sequence Parallelism (vision) & Tensor Parallelism (language)
# 4 GPUs, parallel_size=4, dp_size=1, local batch=2, global batch=2
debug: false

# Vision model configuration - Sequence Parallelism
vision:
  model_type: "qwen2_5_vl"
  model_name: "Qwen/Qwen2.5-VL-7B-Instruct"
  parallelism: "sequence"
  dtype: "bfloat16"
  attention_backend: "flash_attention_2"
  activation_checkpointing: true
  autocast: true
  zero_stage: 1

# Text model configuration - Tensor Parallelism
text:
  model_type: "qwen2_5_vl"
  model_name: "Qwen/Qwen2.5-VL-7B-Instruct"
  parallelism: "tensor"
  dtype: "bfloat16"
  attention_backend: "flash_attention_2"
  activation_checkpointing: true
  autocast: true
  zero_stage: 1
  autotp_size: null
  tp_overlap_comm: false

# Training configuration
training:
  batch_size: 4  # Local batch size per GPU
  learning_rate: 5e-05
  num_epochs: 1  # Number of training epochs
  num_iterations: 1000  # Number of iterations (batches) per epoch - reduced for debugging
  warmup_steps: 10
  warmup_ratio: 0.03  # Proportion of training steps for LR warmup (takes precedence over warmup_steps if > 0)
  lr_scheduler_type: "cosine"  # Learning rate scheduler: "cosine", "linear", "constant", etc.
  weight_decay: 0.0  # L2 regularization strength (weight decay)
  gradient_accumulation_steps: 1
  seed: 42
  parallel_size: 4  # SP/TP size (number of processes per model)
  dp_size: 1  # No data parallelism
  collocate: true
  clip_grad_norm: true
  max_grad_norm: 1.0
  no_checkpoint: true
  checkpoint_dir: "/tmp/checkpoints"
  log_interval: 1

# Data configuration
data:
  datasets:
    - mscoco2017_train_captions
  data_registry:
    mscoco2017_train_captions:
      annotation_path: "/mnt/local_storage/mscoco2017/annotations/coco2017_train_qwen.json"
      data_path: "/mnt/local_storage/mscoco2017"
    mscoco2017_val_captions:
      annotation_path: "/mnt/local_storage/mscoco2017/annotations/coco2017_val_qwen.json"
      data_path: "/mnt/local_storage/mscoco2017"
  num_workers: 4
  pin_memory: true
  data_flatten: true
  min_pixels: 200704
  max_pixels: 200704
  force_fixed_size: true

# DeepSpeed configuration
deepspeed:
  reduce_bucket_size: 500000000
